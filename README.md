# Pipeline de Procesamiento de Datos NPS

Sistema automatizado para extraer, limpiar e insertar datos de encuestas NPS (Net Promoter Score) desde archivos Excel a PostgreSQL.

## ğŸ“‹ Tabla de Contenidos

- [Requisitos](#requisitos)
- [ConfiguraciÃ³n Inicial](#configuraciÃ³n-inicial)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Orden de EjecuciÃ³n](#orden-de-ejecuciÃ³n)
- [Scripts Principales](#scripts-principales)
- [Scripts Auxiliares](#scripts-auxiliares)
- [SoluciÃ³n de Problemas](#soluciÃ³n-de-problemas)

---

## ğŸ”§ Requisitos

### Software necesario:
- **Python 3.8+**
- **PostgreSQL 12+**

### LibrerÃ­as Python:
```bash
pip install pandas sqlalchemy psycopg2-binary openpyxl
```

---

## âš™ï¸ ConfiguraciÃ³n Inicial

### 1. Crear base de datos en PostgreSQL

```sql
CREATE DATABASE nps_analytics;
```

**âš ï¸ Importante:** La base de datos se llama `nps_analytics` (nombre de producciÃ³n, no usar "test" o "sample")

### 2. Actualizar credenciales en los scripts

Edita la variable `DB_CONFIG` en los siguientes archivos:

- `test_connection.py`
- `insertar_muestras.py`
- `setup_constraints.py`
- `inspect_database.py`
- `cleanup_database.py`

```python
DB_CONFIG = {
    'host': 'localhost',
    'port': '5432',
    'database': 'nps_analytics',  # â¬…ï¸ Cambiar aquÃ­
    'user': 'postgres',
    'password': 'TU_CONTRASEÃ‘A'   # â¬…ï¸ Cambiar aquÃ­
}
```

### 3. Crear estructura de carpetas

El sistema espera la siguiente estructura (se crea automÃ¡ticamente al ejecutar scripts):

```
datos/
â”œâ”€â”€ data-cruda/          # Archivos Excel originales (input)
â”œâ”€â”€ datos_raw/           # Datos extraÃ­dos en CSV (generado)
â”œâ”€â”€ datos_clean/         # Datos limpios listos para inserciÃ³n (generado)
â”œâ”€â”€ test_connection.py
â”œâ”€â”€ data_extractor.py
â”œâ”€â”€ data_cleaner.py
â”œâ”€â”€ insertar_muestras.py
â”œâ”€â”€ setup_constraints.py
â”œâ”€â”€ inspect_database.py
â””â”€â”€ cleanup_database.py
```

---

## ğŸ“‚ Estructura del Proyecto

### Carpetas de datos:

| Carpeta | PropÃ³sito | Contenido |
|---------|-----------|-----------|
| `data-cruda/` | **Input** - Archivos originales | Archivos Excel mensuales (`agosto_bm_2025.xlsx`, `agosto_bv_2025.xlsx`) |
| `datos_raw/` | **Intermediario** - Datos extraÃ­dos | CSV con datos sin procesar (`agosto_bm_2025_raw.csv`) |
| `datos_clean/` | **Intermediario** - Datos limpios | CSV listos para inserciÃ³n (`agosto_bm_2025_clean.csv`) |

### Tablas de PostgreSQL:

| Tabla | Registros | TamaÃ±o | DescripciÃ³n |
|-------|-----------|--------|-------------|
| `banco_movil_clean` | 1.2M+ | 704 MB | Datos de encuestas Banco MÃ³vil (BM) |
| `banco_virtual_clean` | 5.7K+ | 2 MB | Datos de encuestas Banco Virtual (BV) |

---

## ğŸš€ Orden de EjecuciÃ³n

### Pipeline Completo (Primera Vez)

Sigue este orden exacto para procesar datos nuevos:

#### **Paso 1: Validar ConexiÃ³n a Base de Datos**

```bash
python test_connection.py
```

**Â¿QuÃ© hace?**
- Verifica conectividad a PostgreSQL
- Prueba inserciÃ³n de datos de prueba
- Valida encoding UTF-8 para caracteres especiales

**Resultado esperado:**
```
âœ… ConexiÃ³n exitosa a PostgreSQL
PostgreSQL version: 16.x
âœ… Datos de prueba insertados correctamente
```

---

#### **Paso 2: Extraer Datos de Excel**

```bash
python data_extractor.py
```

**Â¿QuÃ© hace?**
- Lee archivos Excel desde `data-cruda/`
- Extrae hasta 300,000 registros por archivo
- Genera archivos CSV en `datos_raw/`

**Input:** `data-cruda/agosto_bm_2025.xlsx`, `data-cruda/agosto_bv_2025.xlsx`

**Output:** `datos_raw/agosto_bm_2025_raw.csv`, `datos_raw/agosto_bv_2025_raw.csv`

**Resultado esperado:**
```
âœ… ExtraÃ­dos 50,000 registros de agosto_bm_2025.xlsx â†’ datos_raw/agosto_bm_2025_raw.csv
âœ… ExtraÃ­dos 200 registros de agosto_bv_2025.xlsx â†’ datos_raw/agosto_bv_2025_raw.csv
```

---

#### **Paso 3: Limpiar y Transformar Datos**

```bash
python data_cleaner.py
```

**Â¿QuÃ© hace?**
- Lee archivos CSV desde `datos_raw/`
- Corrige encoding UTF-8 malformado (ÃƒÂ³â†’Ã³, ÃƒÂ¡â†’Ã¡)
- Expande JSON de respuestas (solo BM)
- Calcula categorÃ­a NPS (Detractor/Neutral/Promotor)
- Genera archivos CSV limpios en `datos_clean/`

**Input:** `datos_raw/agosto_bm_2025_raw.csv`

**Output:** `datos_clean/agosto_bm_2025_clean.csv`

**Resultado esperado:**
```
âœ… Limpiados 50,000 registros de agosto_bm_2025_raw.csv â†’ datos_clean/agosto_bm_2025_clean.csv
âœ… Limpiados 200 registros de agosto_bv_2025_raw.csv â†’ datos_clean/agosto_bv_2025_clean.csv
```

---

#### **Paso 4: Configurar Restricciones UNIQUE (Solo primera vez)**

```bash
python setup_constraints.py
```

**Â¿QuÃ© hace?**
- Crea restricciones UNIQUE en tablas de producciÃ³n
- Previene duplicados a nivel de base de datos
- **Ejecutar solo una vez** al configurar la base de datos

**Restricciones creadas:**
- `banco_movil_clean`: UNIQUE(record_id, source_file)
- `banco_virtual_clean`: UNIQUE(date_submitted, nps_score_bv, source_file)

**Resultado esperado:**
```
âœ… Constraint creado: banco_movil_clean UNIQUE(record_id, source_file)
âœ… Constraint creado: banco_virtual_clean UNIQUE(date_submitted, nps_score_bv, source_file)
```

---

#### **Paso 5: Insertar Datos en PostgreSQL**

```bash
python insertar_muestras.py
```

**Â¿QuÃ© hace?**
- Lee archivos CSV desde `datos_clean/`
- Verifica si el archivo ya fue insertado (prevenciÃ³n de duplicados)
- Inserta datos en `banco_movil_clean` o `banco_virtual_clean`
- Crea Ã­ndices para consultas rÃ¡pidas

**Input:** `datos_clean/agosto_bm_2025_clean.csv`

**Output:** Registros en tablas PostgreSQL

**PrevenciÃ³n de duplicados:**
- âœ… **AplicaciÃ³n:** Verifica `source_file` antes de insertar
- âœ… **Base de datos:** UNIQUE constraints rechazan duplicados

**Resultado esperado:**
```
âœ… Insertados 50,000 registros en banco_movil_clean desde agosto_bm_2025_clean.csv
âœ… Insertados 200 registros en banco_virtual_clean desde agosto_bv_2025_clean.csv
âš ï¸  Archivo agosto_bm_2025_clean.csv ya fue insertado previamente (omitido)
```

---

### Pipeline Incremental (Meses Posteriores)

Para procesar nuevos meses de datos:

```bash
# 1. Colocar nuevos archivos Excel en data-cruda/
#    Ejemplo: septiembre_bm_2025.xlsx, septiembre_bv_2025.xlsx

# 2. Ejecutar pipeline (sin setup_constraints.py)
python data_extractor.py
python data_cleaner.py
python insertar_muestras.py
```

**âš ï¸ Nota:** `setup_constraints.py` solo se ejecuta una vez. Los siguientes meses solo requieren los pasos 2, 3 y 5.

---

## ğŸ“š Scripts Principales

### 1. test_connection.py
**PropÃ³sito:** Validar configuraciÃ³n de base de datos

**Usa este script cuando:**
- Configuras el sistema por primera vez
- Cambias credenciales de base de datos
- Detectas problemas de conexiÃ³n

**EjecuciÃ³n:**
```bash
python test_connection.py
```

---

### 2. data_extractor.py
**PropÃ³sito:** Extraer datos desde archivos Excel a CSV

**ConfiguraciÃ³n:**
- LÃ­nea 12: `max_records = 300000` (cambiar para extraer menos registros en pruebas)

**Detecta archivos por patrÃ³n:**
- `*_bm_*.xlsx` â†’ Banco MÃ³vil
- `*_bv_*.xlsx` â†’ Banco Virtual

**EjecuciÃ³n:**
```bash
python data_extractor.py
```

---

### 3. data_cleaner.py
**PropÃ³sito:** Limpiar y transformar datos

**Operaciones clave:**
- âœ… CorrecciÃ³n de encoding UTF-8
- âœ… ExpansiÃ³n de JSON `answers` (BM)
- âœ… CÃ¡lculo de NPS score
- âœ… CategorizaciÃ³n (Detractor/Neutral/Promotor)
- âœ… NormalizaciÃ³n de fechas

**EjecuciÃ³n:**
```bash
python data_cleaner.py
```

---

### 4. insertar_muestras.py
**PropÃ³sito:** Insertar datos limpios en PostgreSQL

**CaracterÃ­sticas:**
- âœ… PrevenciÃ³n de duplicados (aplicaciÃ³n + base de datos)
- âœ… InserciÃ³n en lotes (1000 registros por batch)
- âœ… CreaciÃ³n automÃ¡tica de Ã­ndices
- âœ… Logging detallado

**EjecuciÃ³n:**
```bash
python insertar_muestras.py
```

---

## ğŸ› ï¸ Scripts Auxiliares

### setup_constraints.py
**PropÃ³sito:** Configurar restricciones UNIQUE (una sola vez)

**CuÃ¡ndo ejecutar:**
- âœ… Primera vez que configuras la base de datos
- âŒ NO ejecutar en cada inserciÃ³n de datos

**EjecuciÃ³n:**
```bash
python setup_constraints.py
```

---

### inspect_database.py
**PropÃ³sito:** Generar documentaciÃ³n de estructura de base de datos

**Output:** Archivo `database_structure.txt` con:
- Lista de tablas
- Columnas y tipos de datos
- Constraints e Ã­ndices
- Registros de ejemplo
- TamaÃ±o de tablas

**EjecuciÃ³n:**
```bash
python inspect_database.py
```

---

### cleanup_database.py
**PropÃ³sito:** Eliminar tablas obsoletas de prueba

**Modos:**
```bash
# Modo dry-run (solo muestra quÃ© se eliminarÃ­a)
python cleanup_database.py

# Modo ejecuciÃ³n (elimina tablas confirmadas)
python cleanup_database.py --execute
```

**âš ï¸ Tablas protegidas (NUNCA se eliminan):**
- `banco_movil_clean`
- `banco_virtual_clean`

---

## ğŸ› SoluciÃ³n de Problemas

### Error: "No se puede conectar a PostgreSQL"

**SoluciÃ³n:**
1. Verifica que PostgreSQL estÃ© corriendo:
   ```bash
   # Windows
   sc query postgresql-x64-16

   # Linux/Mac
   sudo systemctl status postgresql
   ```
2. Revisa credenciales en `DB_CONFIG`
3. Ejecuta `python test_connection.py`

---

### Error: "IntegrityError: duplicate key value violates unique constraint"

**Causa:** Intentando insertar un archivo que ya existe en la base de datos

**SoluciÃ³n:**
- âœ… Este es el comportamiento esperado (prevenciÃ³n de duplicados)
- El archivo serÃ¡ omitido automÃ¡ticamente
- No requiere acciÃ³n

---

### Error: "UnicodeDecodeError" al leer CSV

**Causa:** Archivo con encoding incorrecto

**SoluciÃ³n:**
1. Verifica que los archivos CSV se guardaron con UTF-8
2. Ejecuta `data_cleaner.py` nuevamente
3. Si persiste, abre el CSV en un editor y guarda con UTF-8

---

### Warning: "JSON invÃ¡lido encontrado"

**Causa:** Campo `answers` con formato JSON corrupto (comÃºn en datos BM)

**SoluciÃ³n:**
- âœ… El script maneja esto automÃ¡ticamente
- Convierte JSON invÃ¡lido a `[]` (array vacÃ­o)
- No detiene el proceso

---

### Pregunta: "Â¿CÃ³mo proceso solo un archivo de prueba?"

**SoluciÃ³n:**
1. Edita `data_extractor.py` lÃ­nea 12:
   ```python
   max_records = 100  # Cambiar de 300000 a 100
   ```
2. Ejecuta pipeline normalmente
3. Restaura `max_records = 300000` para producciÃ³n

---

### Pregunta: "Â¿CÃ³mo verifico que los datos se insertaron correctamente?"

**SoluciÃ³n:**
```bash
# Generar reporte de base de datos
python inspect_database.py

# Revisar archivo generado
cat database_structure.txt
```

O consulta directamente en PostgreSQL:
```sql
-- Contar registros
SELECT COUNT(*) FROM banco_movil_clean;
SELECT COUNT(*) FROM banco_virtual_clean;

-- Ver Ãºltimos 10 registros
SELECT * FROM banco_movil_clean ORDER BY inserted_at DESC LIMIT 10;
```

---

## ğŸ“Š Archivos de Log

El sistema genera logs detallados:

| Archivo | Contenido |
|---------|-----------|
| `data_cleaning.log` | Operaciones de limpieza y transformaciÃ³n |
| `insercion_datos.log` | Inserciones en base de datos, duplicados detectados |

**Revisar logs:**
```bash
# Ãšltimas 50 lÃ­neas de log de limpieza
tail -n 50 data_cleaning.log

# Ãšltimas 50 lÃ­neas de log de inserciÃ³n
tail -n 50 insercion_datos.log
```

---

## ğŸ“ˆ Flujo Visual del Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   data-cruda/       â”‚
â”‚  agosto_bm_2025.xlsxâ”‚ â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                          â”‚ python data_extractor.py
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   data-cruda/       â”‚   â”‚
â”‚  agosto_bv_2025.xlsxâ”‚ â”€â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                          â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   datos_raw/        â”‚
                    â”‚ agosto_bm_2025_raw  â”‚
                    â”‚ agosto_bv_2025_raw  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ python data_cleaner.py
                          â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   datos_clean/      â”‚
                    â”‚ agosto_bm_2025_cleanâ”‚
                    â”‚ agosto_bv_2025_cleanâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ python insertar_muestras.py
                          â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   PostgreSQL        â”‚
                    â”‚ nps_analytics       â”‚
                    â”‚                     â”‚
                    â”‚ banco_movil_clean   â”‚ (1.2M records)
                    â”‚ banco_virtual_clean â”‚ (5.7K records)
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Checklist de Primera EjecuciÃ³n

- [ ] PostgreSQL instalado y corriendo
- [ ] Base de datos `nps_analytics` creada
- [ ] LibrerÃ­as Python instaladas (`pandas`, `sqlalchemy`, `psycopg2-binary`, `openpyxl`)
- [ ] Credenciales actualizadas en todos los scripts (`DB_CONFIG`)
- [ ] Archivos Excel colocados en `data-cruda/`
- [ ] Ejecutado: `python test_connection.py` âœ…
- [ ] Ejecutado: `python data_extractor.py` âœ…
- [ ] Ejecutado: `python data_cleaner.py` âœ…
- [ ] Ejecutado: `python setup_constraints.py` âœ… (solo primera vez)
- [ ] Ejecutado: `python insertar_muestras.py` âœ…
- [ ] Verificado: `python inspect_database.py` âœ…

---

## ğŸ“ Soporte

Para mÃ¡s detalles tÃ©cnicos, consulta:
- [CLAUDE.md](CLAUDE.md) - DocumentaciÃ³n completa del proyecto
- [PREVENCION_DUPLICADOS.md](PREVENCION_DUPLICADOS.md) - Sistema de prevenciÃ³n de duplicados
- `database_structure.txt` - Esquema de base de datos (generado por `inspect_database.py`)

---

**Ãšltima actualizaciÃ³n:** 2025-10-09
