#!/usr/bin/env python3
"""
======================================================================================
SCRIPT: 05_categorizar_motivos.py
======================================================================================
Sistema de Categorizaci√≥n de Motivos NPS/CSAT

PROP√ìSITO:
    Categoriza autom√°ticamente los motivos de respuestas NPS/CSAT y actualiza
    los campos de categorizaci√≥n en la tabla unificada.

QU√â HACE:
    1. Lee motivos sin categorizar de respuestas_nps_csat
    2. Aplica filtros de ruido (textos sin sentido)
    3. Categoriza usando algoritmo Aho-Corasick (r√°pido)
    4. Calcula scores de confianza
    5. Actualiza campos: categoria, categoria_confianza, es_ruido, razon_ruido

CATEGOR√çAS:
    Definidas en: categorias/categorias.yml

USO:
    # Exploraci√≥n inicial (recomendado primero)
    python 05_categorizar_motivos.py --mode explore --limit 10000

    # Procesamiento completo con actualizaci√≥n de BD
    python 05_categorizar_motivos.py --mode process --batch-size 5000

    # Procesar solo motivos sin categorizar
    python 05_categorizar_motivos.py --mode process --only-uncategorized

SIGUIENTE PASO:
    python 06_analisis_sentimientos.py
======================================================================================
"""

import argparse
import logging
import os
import re
import sys
from collections import Counter, defaultdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import ahocorasick
import pandas as pd
import yaml
from sqlalchemy import create_engine, text

# ============================================================================
# FUNCIONES HELPER B√ÅSICAS
# ============================================================================

def get_engine(db_name='nps_analitycs'):
    """Crea conexi√≥n a PostgreSQL"""
    conn_string = f"postgresql://postgres:postgres@localhost:5432/{db_name}?client_encoding=utf8"
    return create_engine(conn_string)

def load_yaml(file_path):
    """Carga archivo YAML"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def normalize_text(text):
    """Normaliza texto: lowercase, sin acentos, sin puntuaci√≥n extra"""
    if pd.isna(text) or text is None:
        return ""
    text = str(text).lower().strip()
    # Remover acentos
    text = text.replace('√°', 'a').replace('√©', 'e').replace('√≠', 'i')
    text = text.replace('√≥', 'o').replace('√∫', 'u').replace('√±', 'n')
    # Normalizar espacios
    text = re.sub(r'\s+', ' ', text)
    return text

# ============================================================================
# CONFIGURACI√ìN
# ============================================================================

CATEGORIAS_YAML = "categorias/categorias.yml"
MIN_CONFIDENCE_THRESHOLD = 0.3  # Score m√≠nimo para aceptar categorizaci√≥n
LOG_FILE = "categorizacion_datos.log"

# Configuraci√≥n de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============================================================================
# CLASES
# ============================================================================

class TextCleaner:
    """Detecta y filtra textos sin sentido (ruido)"""

    def __init__(self, min_length=3, min_alpha_ratio=0.5):
        self.min_length = min_length
        self.min_alpha_ratio = min_alpha_ratio

    def is_valid(self, text: str) -> Tuple[bool, Optional[str]]:
        """
        Valida si un texto es v√°lido o es ruido
        Returns: (is_valid, reason_if_invalid)
        """
        if pd.isna(text) or not text or not str(text).strip():
            return (False, "texto_vacio")

        text_clean = str(text).strip()

        # Muy corto
        if len(text_clean) < self.min_length:
            return (False, "muy_corto")

        # Demasiados caracteres no alfab√©ticos
        alpha_chars = sum(c.isalpha() for c in text_clean)
        if alpha_chars == 0:
            return (False, "sin_letras")

        ratio = alpha_chars / len(text_clean)
        if ratio < self.min_alpha_ratio:
            return (False, "pocos_caracteres_alfabeticos")

        # Caracteres repetidos (ej: "aaaaaaa", "......")
        if re.search(r'(.)\1{5,}', text_clean):
            return (False, "caracteres_repetidos")

        # Solo puntuaci√≥n
        if re.match(r'^[^\w\s]+$', text_clean):
            return (False, "solo_puntuacion")

        return (True, None)


class CategorizerAhoCorasick:
    """Categorizador usando Aho-Corasick (algoritmo r√°pido para matching de patrones)"""

    def __init__(self, categorias_config: dict):
        self.categorias = categorias_config.get('categorias', [])
        self.automaton = self._build_automaton()

    def _build_automaton(self):
        """Construye el aut√≥mata de Aho-Corasick"""
        A = ahocorasick.Automaton()

        for categoria in self.categorias:
            nombre = categoria['nombre']
            palabras_clave = categoria.get('palabras_clave', [])

            for palabra in palabras_clave:
                palabra_norm = normalize_text(palabra)
                if palabra_norm:
                    # Almacenar tupla (nombre_categoria, palabra_original)
                    A.add_word(palabra_norm, (nombre, palabra))

        A.make_automaton()
        return A

    def categorize(self, text: str) -> Tuple[str, float, dict]:
        """
        Categoriza un texto
        Returns: (categoria, confidence, metadata)
        """
        if not text or pd.isna(text):
            return ("Otros", 0.0, {})

        text_norm = normalize_text(text)
        if not text_norm:
            return ("Otros", 0.0, {})

        # Buscar coincidencias
        matches = defaultdict(list)
        for end_index, (categoria, palabra) in self.automaton.iter(text_norm):
            matches[categoria].append(palabra)

        if not matches:
            return ("Otros", 0.0, {})

        # Calcular score por categor√≠a
        categoria_scores = {}
        for categoria, palabras in matches.items():
            # Score = n√∫mero de palabras clave encontradas
            score = len(palabras)
            categoria_scores[categoria] = score

        # Categor√≠a ganadora
        best_categoria = max(categoria_scores, key=categoria_scores.get)
        best_score = categoria_scores[best_categoria]

        # Calcular confianza (normalizada)
        total_matches = sum(categoria_scores.values())
        confidence = best_score / total_matches if total_matches > 0 else 0.0

        metadata = {
            "palabras_encontradas": matches[best_categoria][:5],  # Primeras 5
            "total_coincidencias": best_score
        }

        return (best_categoria, confidence, metadata)


# ============================================================================
# FUNCIONES PRINCIPALES
# ============================================================================

def explore_categories(engine, categorizer, cleaner, limit=1000):
    """
    Modo exploraci√≥n: muestra estad√≠sticas sin actualizar la BD
    """
    logger.info("=" * 70)
    logger.info("MODO EXPLORACI√ìN - An√°lisis de Categorizaci√≥n")
    logger.info("=" * 70)

    # Leer muestra de motivos sin categorizar
    query = """
        SELECT id, canal, metrica, motivo_texto, score
        FROM respuestas_nps_csat
        WHERE motivo_texto IS NOT NULL
          AND LENGTH(TRIM(motivo_texto)) > 0
          AND categoria IS NULL
        ORDER BY RANDOM()
        LIMIT :limit
    """

    with engine.connect() as conn:
        result = conn.execute(text(query), {"limit": limit})
        rows = result.fetchall()

    if not rows:
        logger.info("No hay motivos sin categorizar")
        return

    logger.info(f"Analizando {len(rows)} motivos...")

    # Estad√≠sticas
    stats = {
        'total': len(rows),
        'validos': 0,
        'ruido': 0,
        'categorias': Counter(),
        'ruido_razones': Counter(),
        'confianza_promedio': 0.0
    }

    confidencias = []

    for row in rows:
        registro_id, canal, metrica, texto, score = row

        # Validar
        is_valid, reason = cleaner.is_valid(texto)

        if not is_valid:
            stats['ruido'] += 1
            stats['ruido_razones'][reason] += 1
        else:
            stats['validos'] += 1
            categoria, confidence, metadata = categorizer.categorize(texto)
            stats['categorias'][categoria] += 1
            confidencias.append(confidence)

    stats['confianza_promedio'] = sum(confidencias) / len(confidencias) if confidencias else 0.0

    # Mostrar resultados
    print("\n" + "=" * 70)
    print("üìä RESULTADOS DE EXPLORACI√ìN")
    print("=" * 70)
    print(f"Total analizado: {stats['total']:,}")
    print(f"Textos v√°lidos: {stats['validos']:,} ({stats['validos']/stats['total']*100:.1f}%)")
    print(f"Textos ruido: {stats['ruido']:,} ({stats['ruido']/stats['total']*100:.1f}%)")
    print(f"\nüìà Confianza promedio: {stats['confianza_promedio']:.3f}")

    print(f"\nüè∑Ô∏è  Top 10 Categor√≠as:")
    for categoria, count in stats['categorias'].most_common(10):
        pct = count / stats['validos'] * 100 if stats['validos'] > 0 else 0
        print(f"  {categoria:40s}: {count:6,} ({pct:5.1f}%)")

    print(f"\nüóëÔ∏è  Razones de Rechazo (Ruido):")
    for razon, count in stats['ruido_razones'].most_common():
        pct = count / stats['ruido'] * 100 if stats['ruido'] > 0 else 0
        print(f"  {razon:30s}: {count:6,} ({pct:5.1f}%)")

    print("\n" + "=" * 70)
    print("üí° Para procesar y actualizar la BD:")
    print("   python 05_categorizar_motivos.py --mode process")
    print("=" * 70)


def process_and_update_database(engine, categorizer, cleaner, batch_size=5000, only_uncategorized=False):
    """
    Modo procesamiento: categoriza y actualiza la BD
    """
    logger.info("=" * 70)
    logger.info("MODO PROCESAMIENTO - Categorizando y Actualizando BD")
    logger.info("=" * 70)

    # Construir WHERE clause
    where_clause = """
        WHERE motivo_texto IS NOT NULL
          AND LENGTH(TRIM(motivo_texto)) > 0
    """
    if only_uncategorized:
        where_clause += " AND categoria IS NULL"

    # Contar total
    with engine.connect() as conn:
        count_result = conn.execute(text(f"SELECT COUNT(*) FROM respuestas_nps_csat {where_clause}")).fetchone()
        total = count_result[0]

    if total == 0:
        logger.info("No hay motivos para procesar")
        return

    logger.info(f"Total a procesar: {total:,}")

    # Estad√≠sticas
    stats = {
        'total': total,
        'procesados': 0,
        'actualizados': 0,
        'ruido': 0,
        'errores': 0,
        'categorias': Counter()
    }

    # Procesar en lotes
    offset = 0
    while offset < total:
        logger.info(f"Procesando lote {offset:,} - {min(offset + batch_size, total):,} de {total:,}")

        # Leer lote
        query = f"""
            SELECT id, motivo_texto
            FROM respuestas_nps_csat
            {where_clause}
            ORDER BY id
            LIMIT :lim OFFSET :off
        """

        with engine.connect() as conn:
            rows = conn.execute(text(query), {"lim": batch_size, "off": offset}).fetchall()

            # Procesar cada registro
            for row in rows:
                registro_id, texto = row

                try:
                    # Validar
                    is_valid, reason = cleaner.is_valid(texto)

                    if not is_valid:
                        # Marcar como ruido
                        update_query = """
                            UPDATE respuestas_nps_csat
                            SET categoria = 'Texto Sin Sentido / Ruido',
                                categoria_confianza = 1.0,
                                es_ruido = TRUE,
                                razon_ruido = :razon
                            WHERE id = :id
                        """
                        conn.execute(text(update_query), {"id": registro_id, "razon": reason})
                        stats['ruido'] += 1
                    else:
                        # Categorizar
                        categoria, confidence, metadata = categorizer.categorize(texto)

                        update_query = """
                            UPDATE respuestas_nps_csat
                            SET categoria = :categoria,
                                categoria_confianza = :confidence,
                                es_ruido = FALSE,
                                razon_ruido = NULL
                            WHERE id = :id
                        """
                        conn.execute(text(update_query), {
                            "id": registro_id,
                            "categoria": categoria,
                            "confidence": round(confidence, 4)
                        })
                        stats['actualizados'] += 1
                        stats['categorias'][categoria] += 1

                    stats['procesados'] += 1

                except Exception as e:
                    logger.error(f"Error procesando registro {registro_id}: {str(e)}")
                    stats['errores'] += 1

            # Commit del lote
            conn.commit()

        offset += batch_size

        # Mostrar progreso
        if stats['procesados'] % 10000 == 0:
            logger.info(f"  Progreso: {stats['procesados']:,}/{total:,} ({stats['procesados']/total*100:.1f}%)")

    # Resumen final
    print("\n" + "=" * 70)
    print("üìä RESUMEN DE CATEGORIZACI√ìN")
    print("=" * 70)
    print(f"Total procesados: {stats['procesados']:,}")
    print(f"Categorizados: {stats['actualizados']:,}")
    print(f"Marcados como ruido: {stats['ruido']:,}")
    print(f"Errores: {stats['errores']:,}")

    print(f"\nüè∑Ô∏è  Top 15 Categor√≠as:")
    for categoria, count in stats['categorias'].most_common(15):
        pct = count / stats['actualizados'] * 100 if stats['actualizados'] > 0 else 0
        print(f"  {categoria:40s}: {count:6,} ({pct:5.1f}%)")

    print("\n" + "=" * 70)
    print("‚úÖ Categorizaci√≥n completada")
    print("\nüéØ SIGUIENTE PASO:")
    print("   python 06_analisis_sentimientos.py")
    print("=" * 70)


# ============================================================================
# MAIN
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description='Categorizaci√≥n de motivos NPS/CSAT')
    parser.add_argument('--mode', choices=['explore', 'process'], required=True,
                        help='Modo de ejecuci√≥n: explore (solo an√°lisis) o process (actualizar BD)')
    parser.add_argument('--db-name', default='nps_analitycs', help='Nombre de la base de datos')
    parser.add_argument('--limit', type=int, default=10000,
                        help='L√≠mite de registros para modo explore')
    parser.add_argument('--batch-size', type=int, default=5000,
                        help='Tama√±o de lote para procesamiento')
    parser.add_argument('--only-uncategorized', action='store_true',
                        help='Procesar solo motivos sin categorizar')
    parser.add_argument('--yes', action='store_true',
                        help='No pedir confirmaci√≥n (modo automatizado)')

    args = parser.parse_args()

    # Cargar configuraci√≥n
    if not os.path.exists(CATEGORIAS_YAML):
        logger.error(f"No se encontr√≥ el archivo de categor√≠as: {CATEGORIAS_YAML}")
        sys.exit(1)

    categorias_config = load_yaml(CATEGORIAS_YAML)

    # Inicializar componentes
    engine = get_engine(args.db_name)
    cleaner = TextCleaner(min_length=3, min_alpha_ratio=0.5)
    categorizer = CategorizerAhoCorasick(categorias_config)

    logger.info(f"Categor√≠as cargadas: {len(categorizer.categorias)}")

    # Ejecutar seg√∫n modo
    if args.mode == "explore":
        explore_categories(engine, categorizer, cleaner, limit=args.limit)

    elif args.mode == "process":
        if args.yes:
            response = "yes"
        else:
            response = input("Esto actualizar√° los campos de categorizaci√≥n en la BD. ¬øContinuar? (yes/no): ")

        if response.lower() == "yes":
            process_and_update_database(
                engine,
                categorizer,
                cleaner,
                batch_size=args.batch_size,
                only_uncategorized=args.only_uncategorized
            )
        else:
            logger.info("Operaci√≥n cancelada por el usuario")


if __name__ == "__main__":
    main()
